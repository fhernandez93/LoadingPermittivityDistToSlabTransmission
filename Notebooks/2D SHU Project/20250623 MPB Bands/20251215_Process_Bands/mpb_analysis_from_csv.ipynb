{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f508f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb5a1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaps(list_freqs,gap_width_tolerance:float=0.005):\n",
    "    flattened_lambdas = np.sort(np.concatenate(list_freqs))\n",
    "    bands = []\n",
    "    gaps_list = np.diff(flattened_lambdas)\n",
    "    for i,gaps in enumerate(gaps_list):\n",
    "        bandgap_lower = flattened_lambdas[i]\n",
    "        bandgap_upper = flattened_lambdas[i + 1]\n",
    "        gap_width = (bandgap_upper-bandgap_lower)/((bandgap_upper+bandgap_lower)/2)\n",
    "        if gap_width>=gap_width_tolerance:\n",
    "            bands.append([bandgap_lower,bandgap_upper,gap_width])\n",
    "    return bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5f5ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../Luis Data/SHU 2D point patterns (N=200)/CTL_Files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa9f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: chi_0.30_posics_Lx_14.1421347_Ly_14.1421347_N_200.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.30_posics_Lx_14.1421347_Ly_14.1421347_N_200.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.30_posics_Lx_14.1421347_Ly_14.1421347_N_200.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.30_posics_Lx_14.1421347_Ly_14.1421347_N_200.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.30_posics_Lx_14.1421347_Ly_14.1421347_N_200.0_rods_sample_5_out.csv\n",
      "Processing file: chi_0.31_posics_Lx_13.9283876_Ly_13.9283876_N_194.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.31_posics_Lx_13.9283876_Ly_13.9283876_N_194.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.31_posics_Lx_13.9283876_Ly_13.9283876_N_194.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.31_posics_Lx_13.9283876_Ly_13.9283876_N_194.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.31_posics_Lx_13.9283876_Ly_13.9283876_N_194.0_rods_sample_5_out.csv\n",
      "Processing file: chi_0.32_posics_Lx_14.0356684_Ly_14.0356684_N_197.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.32_posics_Lx_14.0356684_Ly_14.0356684_N_197.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.32_posics_Lx_14.0356684_Ly_14.0356684_N_197.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.32_posics_Lx_14.0356684_Ly_14.0356684_N_197.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.32_posics_Lx_14.0356684_Ly_14.0356684_N_197.0_rods_sample_5_out.csv\n",
      "Processing file: chi_0.33_posics_Lx_14.0356693_Ly_14.0356693_N_197.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.33_posics_Lx_14.0356693_Ly_14.0356693_N_197.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.33_posics_Lx_14.0356693_Ly_14.0356693_N_197.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.33_posics_Lx_14.0356693_Ly_14.0356693_N_197.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.33_posics_Lx_14.0356693_Ly_14.0356693_N_197.0_rods_sample_5_out.csv\n",
      "Processing file: chi_0.34_posics_Lx_14.2478075_Ly_14.2478075_N_203.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.34_posics_Lx_14.2478075_Ly_14.2478075_N_203.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.34_posics_Lx_14.2478075_Ly_14.2478075_N_203.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.34_posics_Lx_14.2478075_Ly_14.2478075_N_203.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.34_posics_Lx_14.2478075_Ly_14.2478075_N_203.0_rods_sample_5_out.csv\n",
      "Processing file: chi_0.35_posics_Lx_14.0712471_Ly_14.0712471_N_198.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.35_posics_Lx_14.0712471_Ly_14.0712471_N_198.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.35_posics_Lx_14.0712471_Ly_14.0712471_N_198.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.35_posics_Lx_14.0712471_Ly_14.0712471_N_198.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.35_posics_Lx_14.0712471_Ly_14.0712471_N_198.0_rods_sample_5_out.csv\n",
      "Processing file: chi_0.36_posics_Lx_14.2478065_Ly_14.2478065_N_203.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.36_posics_Lx_14.2478065_Ly_14.2478065_N_203.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.36_posics_Lx_14.2478065_Ly_14.2478065_N_203.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.36_posics_Lx_14.2478065_Ly_14.2478065_N_203.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.36_posics_Lx_14.2478065_Ly_14.2478065_N_203.0_rods_sample_5_out.csv\n",
      "Processing file: chi_0.37_posics_Lx_14.0712481_Ly_14.0712481_N_198.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.37_posics_Lx_14.0712481_Ly_14.0712481_N_198.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.37_posics_Lx_14.0712481_Ly_14.0712481_N_198.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.37_posics_Lx_14.0712481_Ly_14.0712481_N_198.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.37_posics_Lx_14.0712481_Ly_14.0712481_N_198.0_rods_sample_5_out.csv\n",
      "Processing file: chi_0.38_posics_Lx_13.8924437_Ly_13.8924437_N_193.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.38_posics_Lx_13.8924437_Ly_13.8924437_N_193.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.38_posics_Lx_13.8924437_Ly_13.8924437_N_193.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.38_posics_Lx_13.8924437_Ly_13.8924437_N_193.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.38_posics_Lx_13.8924437_Ly_13.8924437_N_193.0_rods_sample_5_out.csv\n",
      "Processing file: chi_0.39_posics_Lx_13.9642401_Ly_13.9642401_N_195.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.39_posics_Lx_13.9642401_Ly_13.9642401_N_195.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.39_posics_Lx_13.9642401_Ly_13.9642401_N_195.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.39_posics_Lx_13.9642401_Ly_13.9642401_N_195.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.39_posics_Lx_13.9642401_Ly_13.9642401_N_195.0_rods_sample_5_out.csv\n",
      "Processing file: chi_0.40_posics_Lx_14.2478075_Ly_14.2478075_N_203.0_rods_sample_1_out.csv\n",
      "Processing file: chi_0.40_posics_Lx_14.2478075_Ly_14.2478075_N_203.0_rods_sample_2_out.csv\n",
      "Processing file: chi_0.40_posics_Lx_14.2478075_Ly_14.2478075_N_203.0_rods_sample_3_out.csv\n",
      "Processing file: chi_0.40_posics_Lx_14.2478075_Ly_14.2478075_N_203.0_rods_sample_4_out.csv\n",
      "Processing file: chi_0.40_posics_Lx_14.2478075_Ly_14.2478075_N_203.0_rods_sample_5_out.csv\n"
     ]
    }
   ],
   "source": [
    "extracted_data = {}\n",
    "for dirpath, dirnames, filenames in os.walk(directory):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".csv\"):\n",
    "            print(f\"Processing file: {filename}\")\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            type_sim = \"_\".join(Path(dirpath).parts[-2:])\n",
    "            file_key = Path(filename).stem + \"_\" + type_sim\n",
    "            if file_key not in extracted_data.keys():\n",
    "                extracted_data[file_key]={}\n",
    "            freqs=[]\n",
    "            k_points=[]\n",
    "            with open(file_path, newline='') as csvfile: \n",
    "                reader = csv.reader(csvfile)\n",
    "                for row in reader:\n",
    "                    freqs.append(row[5:])\n",
    "                    k_points.append(row[0])\n",
    "                extracted_data[file_key][\"freqs\"] = freqs\n",
    "                extracted_data[file_key][\"k_points\"] = k_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b67c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory to save figures\n",
    "gap_list = {}\n",
    "save_fig_path = \"./figures_mpb_bands\"\n",
    "os.makedirs(save_fig_path,exist_ok=True)\n",
    "for item in extracted_data.keys():\n",
    "    if len(extracted_data[item][\"freqs\"])==0:\n",
    "        continue\n",
    "    freqs = np.array(extracted_data[item][\"freqs\"][1:],dtype=float)\n",
    "    k_points= np.array(extracted_data[item][\"k_points\"][1:],dtype=float)\n",
    "\n",
    "    for freq_item in freqs.T:\n",
    "        plt.scatter(k_points-1,(freq_item), color=\"blue\",facecolors='none')\n",
    "\n",
    "    tick_labs = [r'$\\Gamma$', r'$X$']\n",
    "    plt.ylabel('frequency (c/a)', size=16)\n",
    "    points_in_between = 5\n",
    "    tick_locs = [i*points_in_between+i for i in range(len(tick_labs))]\n",
    "    title = item\n",
    "    chi = float(re.search(r'chi_([+-]?\\d+(?:\\.\\d+)?)', title).group(1))\n",
    "    sample = float(re.search(r'sample_([+-]?\\d+(?:\\.\\d+)?)', title).group(1))\n",
    "    gap = np.array(get_gaps(freqs[:,100:]))\n",
    "    try:\n",
    "        gap_item = gap[np.argmax(gap[:, 2])]\n",
    "    except:\n",
    "        gap_item=[0,0,0]\n",
    "\n",
    "    plt.fill_between(k_points-1,gap_item[0],gap_item[1], color='red', alpha=0.2)\n",
    "    plt.text(0.5,((gap_item[0]+gap_item[1])/2), rf'$\\Delta \\omega / \\omega_0 = {gap_item[2]*100 :.2f}$%', fontsize = 12)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.xticks(tick_locs, tick_labs)\n",
    "    \n",
    "    plt.title(\"sample: \"+str(sample)+\", chi: \"+str(chi), size=16)\n",
    "    if chi not in gap_list.keys():\n",
    "        gap_list[chi] = {}\n",
    "    if f\"sample_{sample}\" not in gap_list[chi].keys():\n",
    "        gap_list[chi][f\"sample_{sample}\"] = {\"gap_edges\":[], \"gap_center\":[],\"gap_width\":[]}\n",
    "    gap_list[chi][f\"sample_{sample}\"][\"gap_width\"].append(gap_item[2])\n",
    "    gap_list[chi][f\"sample_{sample}\"][\"gap_edges\"].append([gap_item[0],gap_item[1]])\n",
    "    gap_list[chi][f\"sample_{sample}\"][\"gap_center\"].append((gap_item[0]+gap_item[1])/2)\n",
    "    # plt.show()\n",
    "    # raise Exception(\"Stop\")\n",
    "    os.makedirs(f\"{save_fig_path}/{chi}\",exist_ok=True)\n",
    "    plt.savefig(rf\"{save_fig_path}/{chi}/{sample}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9c3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming /AutomationModule is in the root directory of your project\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(rf'H:\\phd stuff\\tidy3d'))\n",
    "from AutomationModule import * \n",
    "\n",
    "import AutomationModule as AM\n",
    "\n",
    "os.makedirs(\"./data\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de551d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM.create_hdf5_from_dict(gap_list,\"./data/20251215_eps_11p56_chi_0p3_0p37_bgw_list.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b79e92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
